# ===========================
# ====== Preset config ======
# ===========================

# if no special requirements, no need to change
APP_HOST=http://192.168.137.1
NGX_HTTP_PORT=3210
NW_API_PORT=8080
NW_WEB_PORT=3080
LOBE_PORT=3000
CASDOOR_PORT=3220
MINIO_PORT=3290
PG_PORT=5432
APP_URL=${APP_HOST}:${NGX_HTTP_PORT}
AUTH_URL=${APP_HOST}:${NGX_HTTP_PORT}/api/auth

# Postgres related, which are the necessary environment variables for DB
POSTGRES_DB=qingling-chat
POSTGRES_PASSWORD=gAlC9sQqAkPfS4cs

AUTH_CASDOOR_ISSUER=${APP_HOST}:3220
# # Casdoor secret
AUTH_CASDOOR_ID=a387a4892ee19b1a2249
# # openssl rand -hex 20
AUTH_CASDOOR_SECRET=64ab4c7f246b9ecd7a4769a1bd0af26920a28b17
# CASDOOR_WEBHOOK_SECRET=

# MinIO S3 configuration
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=G76ZgoCN7ljtO7
MINIO_LOBE_BUCKET=qingling

# Configure the bucket information of MinIO
S3_PUBLIC_DOMAIN=${APP_HOST}:3290
S3_ENDPOINT=${APP_HOST}:3290
S3_REGION=

# Configure for casdoor
origin=${APP_HOST}:3220
ENABLE_AUTH_PROTECTION=1

# add a access code to lock your lobe-chat application, you can set a long password to avoid leaking. If this value contains a comma, it is a password array.
# openssl rand -base64 20 | tr -dc 'a-zA-Z0-9_@!' | head -c 16
ACCESS_CODE=GApDEtTJoikYZL

# Specify your API Key selection method, currently supporting `random` and `turn`.
# API_KEY_SELECT_MODE=random

#NEXT_PUBLIC_SENTRY_DSN=0

# # The local/remote ollama service url
# OLLAMA_PROXY_URL=http://host.docker.internal:11434
# OLLAMA_MODEL_LIST=deepseek-r1:32b,qwen2.5:32b,qwq
# ENABLED_OPENAI=0
ENABLED_OLLAMA=0

DEFAULT_AGENT_CONFIG="model=deepseek-r1:32b;provider=openai;chatConfig.searchFCModel.provider=openai;chatConfig.searchFCModel.model=deepseek-r1:32b"
SYSTEM_AGENT="default=openai/deepseek-r1:32b"

DEFAULT_FILES_CONFIG="embedding_model=openai/bge-m3:567m,reranker_model=cohere/rerank-english-v3.0,query_mode=full_text"
# QINGLING_CUSTOMIZED=1

########################################
########## AI Provider Service #########
########################################

### OpenAI ###

# you openai api key
OPENAI_API_KEY=ollama

# # use a proxy to connect to the OpenAI API
OPENAI_PROXY_URL=http://host.docker.internal:11434/v1

# # add your custom model name, multi model separate by comma. for example gpt-3.5-1106,gpt-4-1106
OPENAI_MODEL_LIST_DEEPSEEK="deepseek-r1:32b=Deepseek R1 32B<65536:reasoning:fc"
OPENAI_MODEL_LIST_QWEN="qwen3:32b=Qwen3 32B<65536:fc"
# ,qwq=QWQ 32B<65536:reasoning
OPENAI_MODEL_LIST_ADD="${OPENAI_MODEL_LIST_DEEPSEEK},${OPENAI_MODEL_LIST_QWEN}"
OPENAI_MODEL_LIST_DEL="-o3,-o4-mini,-gpt-4.1,-gpt-4.1-mini,-chatgpt-4o-latest"
OPENAI_MODEL_LIST="${OPENAI_MODEL_LIST_ADD},${OPENAI_MODEL_LIST_DEL}"


### Azure OpenAI ###

# you can learn azure OpenAI Service on https://learn.microsoft.com/en-us/azure/ai-services/openai/overview
# use Azure OpenAI Service by uncomment the following line

# The API key you applied for on the Azure OpenAI account page, which can be found in the "Keys and Endpoints" section.
# AZURE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# The endpoint you applied for on the Azure OpenAI account page, which can be found in the "Keys and Endpoints" section.
# AZURE_ENDPOINT=https://docs-test-001.openai.azure.com

# Azure's API version, follows the YYYY-MM-DD format
# AZURE_API_VERSION=2024-10-21


### Anthropic Service ####

# ANTHROPIC_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# use a proxy to connect to the Anthropic API
# ANTHROPIC_PROXY_URL=https://api.anthropic.com


### Google AI  ####

# GOOGLE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx


### AWS Bedrock  ###

# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=xxxxxxxxxxxxxxxxxxx
# AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx


### Ollama AI ####

# You can use ollama to get and run LLM locally, learn more about it via https://github.com/ollama/ollama

# The local/remote ollama service url
# OLLAMA_PROXY_URL=http://127.0.0.1:11434

# OLLAMA_MODEL_LIST=your_ollama_model_names


### OpenRouter Service ###

# OPENROUTER_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# OPENROUTER_MODEL_LIST=model1,model2,model3


### Mistral AI ###

# MISTRAL_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### Perplexity Service ###

# PERPLEXITY_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### Groq Service ####

# GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

#### 01.AI Service ####

# ZEROONE_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### TogetherAI Service ###

# TOGETHERAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### ZhiPu AI ###

# ZHIPU_API_KEY=xxxxxxxxxxxxxxxxxxx.xxxxxxxxxxxxx

### Moonshot AI  ####

# MOONSHOT_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### Minimax AI  ####

# MINIMAX_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### DeepSeek AI  ####

# DEEPSEEK_PROXY_URL=https://api.deepseek.com/v1
# DEEPSEEK_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### Qwen AI  ####

# QWEN_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### Cloudflare Workers AI  ####

# CLOUDFLARE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# CLOUDFLARE_BASE_URL_OR_ACCOUNT_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### SiliconCloud AI  ####

# SILICONCLOUD_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx


### TencentCloud AI  ####

# TENCENT_CLOUD_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### PPIO ####

# PPIO_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

### INFINI-AI ###

# INFINIAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

########################################
############ Market Service ############
########################################

# The LobeChat agents market index url
# AGENTS_INDEX_URL=https://chat-agents.lobehub.com

########################################
############ Plugin Service ############
########################################

# The LobeChat plugins store index url
# PLUGINS_INDEX_URL=https://chat-plugins.lobehub.com

# set the plugin settings
# the format is `plugin-identifier:key1=value1;key2=value2`, multiple settings fields are separated by semicolons `;`, multiple plugin settings are separated by commas `,`.
# PLUGIN_SETTINGS=search-engine:SERPAPI_API_KEY=xxxxx

########################################
####### Doc / Changelog Service ########
########################################

# Use in Changelog / Document service cdn url prefix
# DOC_S3_PUBLIC_DOMAIN=https://xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Use in dev cdn workflow
# DOC_S3_ACCESS_KEY_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# DOC_S3_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx


########################################
##### S3 Object Storage Service ########
########################################

# S3 keys
# S3_ACCESS_KEY_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# S3_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Bucket name
# S3_BUCKET=lobechat

# Bucket request endpoint
# S3_ENDPOINT=https://xxxxxxxxxxxxxxxxxxxxxxxxxxxxx.r2.cloudflarestorage.com

# Public access domain for the bucket
# S3_PUBLIC_DOMAIN=https://s3-for-lobechat.your-domain.com

# Bucket region, such as us-west-1, generally not needed to add
# but some service providers may require configuration
# S3_REGION=us-west-1


########################################
############ Auth Service ##############
########################################


# Clerk related configurations

# Clerk public key and secret key
#NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_live_xxxxxxxxxxx
#CLERK_SECRET_KEY=sk_live_xxxxxxxxxxxxxxxxxxxxxx

# you need to config the clerk webhook secret key if you want to use the clerk with database
#CLERK_WEBHOOK_SECRET=whsec_xxxxxxxxxxxxxxxxxxxxxx


# NextAuth related configurations
# NEXT_PUBLIC_ENABLE_NEXT_AUTH=1
NEXT_AUTH_SECRET=ArZ7XQkfdgkV5FZXrVv5MTXkHQTMGFZCFp+YIqypbd8=

# Auth0 configurations
# AUTH_AUTH0_ID=
# AUTH_AUTH0_SECRET=
# AUTH_AUTH0_ISSUER=https://your-domain.auth0.com

########################################
########## Server Database #############
########################################

# Specify the service mode as server if you want to use the server database
NEXT_PUBLIC_SERVICE_MODE=server

# Postgres database URL
# DATABASE_URL=postgres://username:password@host:port/database

# use `openssl rand -base64 32` to generate a key for the encryption of the database
# we use this key to encrypt the user api key and proxy url
KEY_VAULTS_SECRET=wKuATOBdmBmbCx99aLdGbEXY9tzyaO6M59v3csG47WE=

# Specify the Embedding model and Reranker model(unImplemented)
# DEFAULT_FILES_CONFIG="embedding_model=openai/embedding-text-3-small,reranker_model=cohere/rerank-english-v3.0,query_mode=full_text"
